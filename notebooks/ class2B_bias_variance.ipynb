{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "173607e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "prng = np.random.RandomState(20250310)\n",
    "\n",
    "%precision 3\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-variance decomposition\n",
    "\n",
    "$$\n",
    "Y = f(X) + \\varepsilon\n",
    "$$\n",
    "\n",
    "Our goal is to find a prediction function based on some data ${(X_i, Y_i), ..., (X_n, Y_n)}$ that approximates the true function well.\n",
    "\n",
    "We can decompose the prediction error of our model into the sum of the bias (squared) and the variance of the model (plus the irreducible error).\n",
    "\n",
    "*Question:* Why is it called \"irreducible error\"?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "\n",
    "No matter how perfect our model becomes, we cannot reduce prediction error to zero. This remaining 'irreducible error' exists because real-world data contains inherent randomness and unmeasured variables that influence outcomes. These unpredictable elements represent the fundamental noise in any system that no model can capture.\n",
    "\n",
    "</details>\n",
    "\n",
    "To prove the statement above, let's decompose the expected prediction error:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    E\\left[\\left(Y - \\hat{f}(X)\\right)^2\\right] &= E\\left[\\left(f(X) + \\varepsilon - \\hat{f}(X)\\right)^2\\right] \\\\\n",
    "        &= E\\left[\\left(f(X) - \\hat{f}(X)\\right)^2\\right] + 2E\\left[\\varepsilon(f(X) - \\hat{f}(X))\\right] + E\\left[\\varepsilon^2\\right] \\\\\n",
    "        &= E\\left[\\left(f(X) - \\hat{f}(X)\\right)^2\\right] + 2\\underbrace{E[\\varepsilon]}_{=0}E\\left[f(X) - \\hat{f}(X)\\right] + E\\left[\\varepsilon^2\\right] \\\\\n",
    "        &= E\\left[\\left(f(X) - E[\\hat{f}(X)] + E[\\hat{f}(X)] - \\hat{f}(X)\\right)^2\\right] + E\\left[\\varepsilon^2\\right] \\\\\n",
    "        &= E\\left[\\left(f(X) - E[\\hat{f}(X)]\\right)^2\\right] + 2\\underbrace{E\\left[\\left(f(X) - E[\\hat{f}(X)]\\right)\\left(E[\\hat{f}(X)] - \\hat{f}(X)\\right)\\right]}_{=f(x)\\left(E[\\hat{f}(X)] - E[\\hat{f}(X)]\\right) - E[\\hat{f}(X)]^2 + E[\\hat{f}(X)]^2 = 0} + E\\left[\\left(E[\\hat{f}(X)] - \\hat{f}(X)\\right)^2\\right] + E\\left[\\varepsilon^2\\right] \\\\\n",
    "    \n",
    "        &= \\left(\\underbrace{f(X) - E[\\hat{f}(X)]}_{\\text{Bias}} \\right)^2 + \\underbrace{E\\left[\\left(E[\\hat{f}(X)] - \\hat{f}(X)\\right)^2\\right]}_{\\text{Variance}} + \\underbrace{E\\left[\\varepsilon^2\\right]}_{\\text{Irreducible error}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus, MSE = Squared Bias + Variance + Irreducible error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21ddb8",
   "metadata": {},
   "source": [
    "# Illustrating bias-variance trade-off: Linear vs quadratic model\n",
    "\n",
    "## Our problem\n",
    "\n",
    "Let's start with a simple linear model:\n",
    "\n",
    "$$\n",
    "Y = f(X) + \\varepsilon = \\beta_1 X^2 + \\beta_2 X + \\varepsilon\n",
    "$$\n",
    "\n",
    "The true model is:\n",
    "\n",
    "$$\n",
    "f(X) = X^2 - 1.5 X\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "fa8279ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trueModel(x):\n",
    "    y = x**2 - 1.5*x\n",
    "    return y\n",
    "\n",
    "def generateData(prng, sample_size):\n",
    "    x = prng.uniform(0, 1, size=sample_size)\n",
    "    y_true = trueModel(x)\n",
    "    y = y_true + prng.normal(0, 1, size=sample_size)\n",
    "\n",
    "    feature_df = pd.DataFrame({'x': x})\n",
    "    return feature_df, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8170f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "features, y = generateData(prng, sample_size=100)\n",
    "\n",
    "plt.plot(features['x'].sort_values(), trueModel(features['x'].sort_values()), label=\"Expected Y\", color='darkred')\n",
    "plt.scatter(features['x'], y, label=\"Observed Y\", alpha=0.5)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Y vs X\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's performance at a single point: X=0.5 (y = -0.5)\n",
    "test_data = pd.DataFrame({'x': [0.5]})\n",
    "trueModel(test_data['x'])[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43f411",
   "metadata": {},
   "source": [
    "## Estimate two models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b6514",
   "metadata": {},
   "source": [
    "### Technical detour: pandas Dataframe vs Series\n",
    "\n",
    "If `data` is a pandas Dataframe, then `data['x']` is a pandas Series. Pandas Series are like numpy arrays but with additional functionality.\n",
    "If you would like to pass a Dataframe with a single column, you can use the `data[['x']]` syntax. (Think of it as the standard way of selecting columns from a Dataframe that you would do with  `data[list_of_columns]` syntax, e.g. `data[['x', 'y']]`. For a single column, this just collapses to `data[['x']]`.)\n",
    "If you would like to get a scalar value, you should index it again. To get the first element (which could be the only element), you can use `data['x'][0]`.\n",
    "\n",
    "Be careful with the different types of objects you get back. Some methods expect pandas Dataframes, others might expect scalars, or numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4025a859",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "\n",
    "- Create a Pipeline with a single step: LinearRegression\n",
    "- Fit the model\n",
    "- Get the prediction for X_0 = 0.5 (use the `test_data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73258d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_model = Pipeline([\n",
    "    (\"add-quadratic-term\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('lm', LinearRegression())\n",
    "])\n",
    "squared_model.fit(features, y)\n",
    "\n",
    "squared_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10c0bba",
   "metadata": {},
   "source": [
    "## Monte Carlo simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d3855c",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "- Extend the cell below to run the Monte Carlo simulation and store the data in the `predictions` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "385ebda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of Monte Carlo iterations and sample size\n",
    "num_iterations = 1000\n",
    "sample_size = 100\n",
    "\n",
    "# Initialize arrays to store the results\n",
    "predictions = np.empty((num_iterations, 2))\n",
    "\n",
    "# Perform the Monte Carlo simulation\n",
    "for i in range(num_iterations):\n",
    "\n",
    "    features, y = generateData(prng, sample_size=sample_size)\n",
    "    \n",
    "    simple_fit = # TBA\n",
    "    squared_fit = # TBA\n",
    "    \n",
    "    predictions[i, 0] = # TBA\n",
    "    predictions[i, 1] = # TBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbdeade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the results\n",
    "pd.DataFrame({\n",
    "    'model': ['simple', 'squared'],\n",
    "    'x0': test_data['x'][0],\n",
    "    'bias': np.mean(predictions - trueModel(test_data['x'])[0], axis=0),\n",
    "    'variance': np.var(predictions, axis=0),\n",
    "    'mse': np.mean(np.square(predictions - trueModel(test_data['x'])[0]), axis=0)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ac86c",
   "metadata": {},
   "source": [
    "Note that on average the simpler model gave better predictions than the *true* model!\n",
    "\n",
    "*Question:* Which of the parameters (`num_iterations`, `sample_size`) should be changed to alter this result?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "\n",
    "The `sample_size` parameter along with the implicit parameter of the variance of the noise term $\\varepsilon$ together determine the signal-to-noise ratio. With larger samples, the true patterns become more distinguishable from random noise, which enables the complex model to benefit more from its accurate representation of the true relationship than what it loses on its higher variance. Try estimate the models with `sample_size=500` and compare the results with the ones above.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a2319",
   "metadata": {},
   "source": [
    "##  Gather some intuition for bias-variance trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8be735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the number of Monte Carlo iterations and sample size\n",
    "num_iterations = 100\n",
    "sample_sizes = [100, 500]\n",
    "\n",
    "# Initialize chart\n",
    "fig, (axs) = plt.subplots(2, 2, sharey=True, sharex=True)\n",
    "\n",
    "beta1_predictions = np.empty((num_iterations, 2, 2))\n",
    "\n",
    "# Perform the Monte Carlo simulation\n",
    "for i in range(num_iterations):\n",
    "\n",
    "    for ids, s in enumerate(sample_sizes):\n",
    "        features, y = generateData(prng, sample_size=s)\n",
    "\n",
    "        simple_model = simple_model.fit(features, y)\n",
    "        squared_model = squared_model.fit(features, y)\n",
    "\n",
    "        simple_prediction = simple_model.predict(features.sort_values(by='x'))  # we need to sort them for the plot\n",
    "        squared_prediction = squared_model.predict(features.sort_values(by='x'))\n",
    "        \n",
    "        beta1_predictions[i, ids, 0] = simple_model['lm'].coef_[0]\n",
    "        beta1_predictions[i, ids, 1] = squared_model['lm'].coef_[0]\n",
    "\n",
    "        axs[ids, 0].plot(features['x'].sort_values(), simple_prediction, color='black', alpha=0.05)\n",
    "        axs[ids, 1].plot(features['x'].sort_values(), squared_prediction, color='black', alpha=0.05)\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.plot(features['x'].sort_values(), trueModel(features['x'].sort_values()), color='darkred', linestyle='dashed')\n",
    "    ax.axvline(x=0.5, ymin=0, ymax=1, linestyle=\"dotted\", color=\"black\", linewidth=1)\n",
    "    ax.annotate(r\"$X_0$\", xy=(0.5, ax.get_ylim()[1]), xytext=(0.55, 0.5), fontsize=10)\n",
    "    \n",
    "fig.suptitle(r\"Predicted $\\hat{f}(X)$ vs $f(X)$\")\n",
    "axs[0, 0].set_title(\"Linear (n=100)\")\n",
    "axs[0, 1].set_title(\"Quadratic (n=100)\")\n",
    "axs[1, 0].set_title(\"Linear (n=1000)\")\n",
    "axs[1, 1].set_title(\"Quadratic (n=1000)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2479f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axs) = plt.subplots(2, 2, sharey=True, sharex=True)\n",
    "for ax1 in range(2):\n",
    "    for ax2 in range (2):\n",
    "        s = sns.kdeplot(beta1_predictions[:, ax1, ax2], ax=axs[ax1, ax2])\n",
    "        s.axvline(x=-1.5, ymin=0, ymax=1, linestyle=\"dashed\", color=\"black\", linewidth=1)\n",
    "\n",
    "fig.suptitle(r\"Sampling distribution of $\\beta_1$\")\n",
    "axs[0, 0].set_title(\"Linear (n=100)\")\n",
    "axs[0, 1].set_title(\"Quadratic (n=100)\")\n",
    "axs[1, 0].set_title(\"Linear (n=1000)\")\n",
    "axs[1, 1].set_title(\"Quadratic (n=1000)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e10ce",
   "metadata": {},
   "source": [
    "![Bias-Variance Tradeoff](bias-variance-tradeoff.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5826792",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CEU-ML)",
   "language": "python",
   "name": "ceu-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
