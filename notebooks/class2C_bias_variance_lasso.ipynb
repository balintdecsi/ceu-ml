{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d839d782-c838-4d46-b5d6-439a9fbbfbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "prng = np.random.RandomState(20250310)\n",
    "\n",
    "%precision 3\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c37de50",
   "metadata": {},
   "source": [
    "# Illustrating bias-variance trade-off: Univariate vs multivariate model\n",
    "\n",
    "## Our problem\n",
    "\n",
    "Let\"s start with a simple linear model:\n",
    "\n",
    "$$\n",
    "Y = f(X) + \\varepsilon = \\beta_1 X_1 + \\beta_2 X_2 + \\varepsilon\n",
    "$$\n",
    "\n",
    "The true model is:\n",
    "\n",
    "$$\n",
    "f(X) = X_1 + X_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2e7b8b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trueModel(x1, x2):\n",
    "    y = x1 + x2\n",
    "    return y\n",
    "\n",
    "def generateData(prng, sample_size):\n",
    "    features = [prng.uniform(0, 1, size=sample_size) for _ in range(3)]\n",
    "    y_true = trueModel(features[0], features[1])\n",
    "    y = y_true + prng.normal(0, 2, size=sample_size) # sigma(epsilon) = 2\n",
    " \n",
    "    feature_df = pd.DataFrame({\n",
    "        'x1': features[0],\n",
    "        'x2': features[1]\n",
    "    })\n",
    "\n",
    "    return feature_df, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08913b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's performance at a single point: X=0.5\n",
    "test_data = pd.DataFrame({'x1': [0], 'x2': [0]})\n",
    "trueModel(test_data['x1'], test_data['x2'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650dfc3b",
   "metadata": {},
   "source": [
    "## Estimate two models: Linear Regression and Lasso\n",
    "\n",
    "Lasso recap: optimize for the sum of squared residuals (like simple OLS) + a penalty term (= sum of the absolute values of the coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18c4e4f",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "\n",
    "- Extend the code below to estimate two models: a simple linear regression and a Lasso\n",
    "- As we won't do any feature engineering here, there is no need for `Pipeline`\n",
    "- For Lasso, use the default penalty parameter but control the random state with our pseudo-random number generator (`prng`)\n",
    "- Get predictions for the (0, 0) point for both models (you can use the `test_data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3549cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 20\n",
    "\n",
    "X, y = generateData(prng, sample_size)\n",
    "\n",
    "lm = # TBA\n",
    "lasso = # TBA\n",
    "\n",
    "# TBA\n",
    "\n",
    "print(\"Linear model prediction: \", # TBA)\n",
    "print(\"Lasso prediction: \", # TBA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767361c1",
   "metadata": {},
   "source": [
    "## Monte Carlo simulation\n",
    "\n",
    "**TODO**:\n",
    "\n",
    "- Extend the code below to run a Monte Carlo simulation\n",
    "- For each realization of data, we estimate 1+20 models: a simple linear regression and 20 different Lasso models with various penalty parameters (collected in `alphas_to_try`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "eba328de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo simulation\n",
    "\n",
    "n_iterations = 1000\n",
    "alphas_to_try = np.linspace(0.01, 0.5, num=20)\n",
    "\n",
    "lm_predictions = np.empty(n_iterations)\n",
    "lasso_predictions = np.empty((n_iterations, len(alphas_to_try)))\n",
    "lasso_n_coeffs = np.empty((n_iterations, len(alphas_to_try)))\n",
    "\n",
    "# Perform the Monte Carlo simulation\n",
    "for i in range(n_iterations):\n",
    "\n",
    "    X, y = generateData(prng, sample_size)\n",
    "\n",
    "    # TBA\n",
    "    lm_predictions[i] = # TBA\n",
    "\n",
    "    for ida, a in enumerate(alphas_to_try):\n",
    "        # TBA\n",
    "        lasso_predictions[i, ida] = # TBA\n",
    "        lasso_n_coeffs[i, ida] = np.count_nonzero(# TBA)  # we would like to count the non-zero coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6428bad",
   "metadata": {},
   "source": [
    "Linear Regression could be interpreted as a special case of Lasso with alpha = 0. Let's concatenate the predictions of the two models. (*Note that `lm_predictions` is a 1D array so first we need to reshape it to a 2D array with `reshape(-1, 1)`.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fbdb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.concatenate([lm_predictions.reshape(-1, 1), lasso_predictions], axis=1)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a5360d3a-0893-4cdf-a886-f35d279e47ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.concatenate([[0], alphas_to_try])\n",
    "biases = np.mean(predictions - trueModel(test_data['x1'], test_data['x2'])[0], axis=0)\n",
    "variances = np.var(predictions, axis=0)\n",
    "mses = np.mean(np.square(predictions - trueModel(test_data['x1'], test_data['x2'])[0]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e462d0-2a62-4136-9651-a808bd73ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, biases**2, label='Bias^2')\n",
    "plt.plot(alphas, variances, label='Variance')\n",
    "plt.plot(alphas, mses, label='MSE')\n",
    "plt.xlabel('Penalty parameter')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b94095",
   "metadata": {},
   "source": [
    "Penalized regression performs better than the true (unpenalized) model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1171ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_num_coeffs = np.concatenate([[2], np.mean(lasso_n_coeffs, axis=0)])\n",
    "plt.plot(alphas, avg_num_coeffs, label='Avg number of non-zero coefficients')\n",
    "plt.xlabel('Penalty parameter')\n",
    "plt.title('Variable selection in Lasso by the penalty parameter')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55790d56",
   "metadata": {},
   "source": [
    "## Finding the best penalty parameter with cross-validation (hyperparameter tuning)\n",
    "\n",
    "**TODO**:\n",
    "\n",
    "- Extend the code below to run a grid search over the alpha values using `GridSearchCV()` (~ repeat the same exerice as we did above but with cross-validation on the same dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593963d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generateData(prng, sample_size)\n",
    "lasso_cv = # TBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f5bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcffd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f536956",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Coefficients of the best model: beta_1={lasso_cv.best_estimator_.coef_[0]}, beta_2={lasso_cv.best_estimator_.coef_[1]}\")\n",
    "print(f\"Intercept of the best model: {lasso_cv.best_estimator_.intercept_:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea98b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract alpha values and scores for all 10 folds\n",
    "alphas = lasso_cv.cv_results_['param_alpha'].data\n",
    "mean_scores = -lasso_cv.cv_results_['mean_test_score']\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot individual fold scores\n",
    "for i in range(10):  # For all 10 folds\n",
    "    fold_key = f'split{i}_test_score'\n",
    "    fold_scores = -lasso_cv.cv_results_[fold_key]  # Negate to get MSE\n",
    "    plt.plot(alphas, fold_scores, 'o-', alpha=0.4, linewidth=1, label=f'Fold {i+1}')\n",
    "\n",
    "# Plot the mean score with heavier line\n",
    "plt.plot(alphas, mean_scores, 'o-', linewidth=3, color='black', label='Mean')\n",
    "\n",
    "# Mark the best alpha\n",
    "best_alpha = lasso_cv.best_params_['alpha']\n",
    "plt.axvline(x=best_alpha, color='darkred', linestyle='--', label=f'Best alpha: {best_alpha}')\n",
    "\n",
    "plt.xlabel(\"Penalty parameter\")\n",
    "plt.ylabel(\"Mean Squared Error (MSE)\")\n",
    "plt.title(\"Cross-validation scores across all 10 folds\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3219f",
   "metadata": {},
   "source": [
    "Here we can only cook from the given data (n=20). In the previous example, we repeated the experiment 1000 times, allowing us to measure the average performance of the models across many possible datasets (so we basically cooked from 1000x20 data points). In contrast, cross-validation works with only the single available dataset, which better reflects the real life situation where we must estimate performance using only the data at hand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CEU-ML)",
   "language": "python",
   "name": "ceu-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
